{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b8f64e-5a27-4acc-b2ff-7381b302ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/python/current/bin/python\n",
      "Python 3.10.8\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "which python\n",
    "python --version\n",
    "#python -m ipykernel install --name py3.10-env --user\n",
    "pip install -q tqdm openai elasticsearch pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45c958-641b-4527-a83a-7738fd81f2b3",
   "metadata": {},
   "source": [
    "**Restart jupuyter lab**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8dd1c-91a8-47aa-b131-59660cfcbc5b",
   "metadata": {},
   "source": [
    "## Q1. Running Elastic \n",
    "\n",
    "Run Elastic Search 8.4.3, and get the cluster information. If you run it on localhost, this is how you do it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3aaf26-4f92-494c-a068-41ef79ed4718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811f62315da074b7e464fcdd9a5abf0c316b988d3b92502bda39c53b6f83455\n"
     ]
    }
   ],
   "source": [
    "# !docker kill $(docker ps -q -f name=elasticsearch)\n",
    "!docker run --rm -it -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da17f3-a174-479f-8092-6c1af6760d0e",
   "metadata": {},
   "source": [
    "What's the `version.build_hash` value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e73edf3-6098-4b43-b0a1-4e50565349da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m\"42f05b9372a9a4a470db3b52817899b99a76ee73\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!curl -s localhost:9200 | jq .version.build_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae40023-6bea-4d0e-93a3-3f3ae416e183",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Now let's get the FAQ data. You can run this snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a5b40e4-4581-4af6-8a4b-fc634d1f5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "435e69c9-87b1-48bd-9276-b121a6783b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs count: 948\n",
      "Docs samples: [\n",
      "    {\n",
      "        \"course\": \"data-engineering-zoomcamp\",\n",
      "        \"question\": \"Course - When will the course start?\",\n",
      "        \"section\": \"General course-related questions\",\n",
      "        \"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\u201cOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon\\u2019t forget to register in DataTalks.Club's Slack and join the channel.\"\n",
      "    },\n",
      "    {\n",
      "        \"course\": \"data-engineering-zoomcamp\",\n",
      "        \"question\": \"Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?\",\n",
      "        \"section\": \"General course-related questions\",\n",
      "        \"text\": \"It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.\"\n",
      "    },\n",
      "    {\n",
      "        \"course\": \"data-engineering-zoomcamp\",\n",
      "        \"question\": \"Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?\",\n",
      "        \"section\": \"General course-related questions\",\n",
      "        \"text\": \"You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.\"\n",
      "    },\n",
      "    {\n",
      "        \"course\": \"data-engineering-zoomcamp\",\n",
      "        \"question\": \"Are we still using the NYC Trip data for January 2021? Or are we using the 2022 data?\",\n",
      "        \"section\": \"General course-related questions\",\n",
      "        \"text\": \"We will use the same data, as the project will essentially remain the same as last year\\u2019s. The data is available here\"\n",
      "    },\n",
      "    {\n",
      "        \"course\": \"data-engineering-zoomcamp\",\n",
      "        \"question\": \"How to ask questions\",\n",
      "        \"section\": \"General course-related questions\",\n",
      "        \"text\": \"When the troubleshooting guide above does not help resolve it and you need another pair of eyeballs to spot mistakes. When asking a question, include as much information as possible:\\nWhat are you coding on? What OS?\\nWhat command did you run, which video did you follow? Etc etc\\nWhat error did you get? Does it have a line number to the \\u201coffending\\u201d code and have you check it for typos?\\nWhat have you tried that did not work? This answer is crucial as without it, helpers would ask you to do the suggestions in the error log first. Or just read this FAQ document.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "_samples=json.dumps(documents[:int(len(documents) * 0.05):10],sort_keys=True, indent=4)\n",
    "print(f\"Docs count: {len(documents)}\\nDocs samples: {_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504876a8-4ad3-49a5-aac1-f46a1564dfea",
   "metadata": {},
   "source": [
    "## Q2. Indexing the data\n",
    "\n",
    "Index the data in the same way as was shown in the course videos. Make the `course` field a keyword and the rest should be text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2b224-359a-4139-aabe-2a5cc908f756",
   "metadata": {},
   "source": [
    "Which function do you use for adding your data to elastic?\n",
    "\n",
    "* `insert`\n",
    "* `index`\n",
    "* `put`\n",
    "* `add`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d441a424-1e73-48fb-9192-a3cb46534913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95208c14-5506-41b6-9dff-9aa3bb26ab3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '3811f62315da',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'nMroIMhcTLWBnXDN_5_HpQ',\n",
       " 'version': {'number': '8.4.3',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73',\n",
       "  'build_date': '2022-10-04T07:17:24.662462378Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.3.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33ad40e5-c903-46ee-9e50-60ec05733371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "966ee38a-062c-42f6-a77a-65b2195345fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:26<00:00, 35.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027762a-771f-46c1-8b6e-9ae7e8c0407d",
   "metadata": {},
   "source": [
    "**Answer**: index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704619a-9451-4b02-a03f-c5d97fbe364a",
   "metadata": {},
   "source": [
    "## Q3. Searching\n",
    "\n",
    "Now let's search in our index. \n",
    "\n",
    "We will execute a query \"How do I execute a command in a running docker container?\". \n",
    "\n",
    "Use only `question` and `text` fields and give `question` a boost of 4, and use `\"type\": \"best_fields\"`.\n",
    "\n",
    "What's the score for the top ranking result?\n",
    "\n",
    "* 94.05\n",
    "* 84.05\n",
    "* 74.05\n",
    "* 64.05\n",
    "\n",
    "Look at the `_score` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29c93c0c-334f-4596-a894-0b97f3025f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_dicts(a: dict, b: dict, path=[]):\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            if isinstance(a[key], dict) and isinstance(b[key], dict):\n",
    "                _merge_dicts(a[key], b[key], path + [str(key)])\n",
    "            elif a[key] != b[key]:\n",
    "                raise Exception('Conflict at ' + '.'.join(path + [str(key)]))\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a\n",
    "    \n",
    "def search(q, index = index_name, es_client=es_client, size=5, fields=None, type_match=\"best_fields\", query_patch:dict = None):\n",
    "    fields = fields or [\"question^4\", \"text\"]\n",
    "    query_patch = query_patch or {}\n",
    "    search_query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": fields,\n",
    "                        \"type\": type_match\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    search_query = _merge_dicts(search_query,query_patch) if query_patch else search_query\n",
    "    return es_client.search(index=index_name, body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc54bff1-f623-47fb-be07-d7ef27bed00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "response = search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "933204d6-b990-4ecd-b058-e6c6cf5193b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_shards\": {\n",
      "        \"failed\": 0,\n",
      "        \"skipped\": 0,\n",
      "        \"successful\": 1,\n",
      "        \"total\": 1\n",
      "    },\n",
      "    \"hits\": {\n",
      "        \"hits\": [\n",
      "            {\n",
      "                \"_id\": \"rTvZRZABteXuJDEWzTCq\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 84.050095,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"machine-learning-zoomcamp\",\n",
      "                    \"question\": \"How do I debug a docker container?\",\n",
      "                    \"section\": \"5. Deploying Machine Learning Models\",\n",
      "                    \"text\": \"Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\"\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"uzvZRZABteXuJDEWly4B\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 75.54128,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"data-engineering-zoomcamp\",\n",
      "                    \"question\": \"PGCLI - running in a Docker container\",\n",
      "                    \"section\": \"Module 1: Docker and Terraform\",\n",
      "                    \"text\": \"In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\\nBelow the usage with values used in the videos of the course for:\\nnetwork name (docker network)\\npostgres related variables for pgcli\\nHostname\\nUsername\\nPort\\nDatabase name\\n$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\\n175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\\nPassword for root:\\nServer: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\\nVersion: 4.0.1\\nHome: http://pgcli.com\\nroot@pg-database:ny_taxi> \\\\dt\\n+--------+------------------+-------+-------+\\n| Schema | Name             | Type  | Owner |\\n|--------+------------------+-------+-------|\\n| public | yellow_taxi_data | table | root  |\\n+--------+------------------+-------+-------+\\nSELECT 1\\nTime: 0.009s\\nroot@pg-database:ny_taxi>\"\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"3DvZRZABteXuJDEW7jHa\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 72.08518,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"mlops-zoomcamp\",\n",
      "                    \"question\": \"Running multiple services in a Docker container\",\n",
      "                    \"section\": \"Module 4: Deployment\",\n",
      "                    \"text\": \"If you are trying to run Flask gunicorn & MLFlow server from the same container, defining both in Dockerfile with CMD will only run MLFlow & not Flask.\\nSolution: Create separate shell script with server run commands, for eg:\\n> \\tscript1.sh\\n#!/bin/bash\\ngunicorn --bind=0.0.0.0:9696 predict:app\\nAnother script with e.g. MLFlow server:\\n>\\tscript2.sh\\n#!/bin/bash\\nmlflow server -h 0.0.0.0 -p 5000 --backend-store-uri=sqlite:///mlflow.db --default-artifact-root=g3://zc-bucket/mlruns/\\nCreate a wrapper script to run above 2 scripts:\\n>\\twrapper_script.sh\\n#!/bin/bash\\n# Start the first process\\n./script1.sh &\\n# Start the second process\\n./script2.sh &\\n# Wait for any process to exit\\nwait -n\\n# Exit with status of process that exited first\\nexit $?\\nGive executable permissions to all scripts:\\nchmod +x *.sh\\nNow we can define last line of Dockerfile as:\\n> \\tDockerfile\\nCMD ./wrapper_script.sh\\nDont forget to expose all ports defined by services!\"\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"zDvZRZABteXuJDEW0DD2\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 51.04628,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"machine-learning-zoomcamp\",\n",
      "                    \"question\": \"How do I copy files from my local machine to docker container?\",\n",
      "                    \"section\": \"5. Deploying Machine Learning Models\",\n",
      "                    \"text\": \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\"\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"zTvZRZABteXuJDEW0TAU\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 49.938507,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"machine-learning-zoomcamp\",\n",
      "                    \"question\": \"How do I copy files from a different folder into docker container\\u2019s working directory?\",\n",
      "                    \"section\": \"5. Deploying Machine Learning Models\",\n",
      "                    \"text\": \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\\\"src/predict.py\\\", \\\"models/xgb_model.bin\\\", \\\"./\\\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan\"\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"max_score\": 84.050095,\n",
      "        \"total\": {\n",
      "            \"relation\": \"eq\",\n",
      "            \"value\": 865\n",
      "        }\n",
      "    },\n",
      "    \"timed_out\": false,\n",
      "    \"took\": 25\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.050095"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(json.dumps(response.body,sort_keys=True, indent=4))\n",
    "response[\"hits\"][\"hits\"][0][\"_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27617f0d-e536-495d-a0e3-cc0032f46c35",
   "metadata": {},
   "source": [
    "**Answer: 84.050095**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644137c-dbd1-4713-aba7-563af5f9cb86",
   "metadata": {},
   "source": [
    "## Q4. Filtering\n",
    "\n",
    "Now let's only limit the questions to `machine-learning-zoomcamp`.\n",
    "\n",
    "Return 3 results. What's the 3rd question returned by the search engine?\n",
    "\n",
    "* How do I debug a docker container?\n",
    "* How do I copy files from a different folder into docker container’s working directory?\n",
    "* How do Lambda container images work?\n",
    "* How can I annotate a graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ee4b2d6-6896-46a5-af7c-5e658c7712e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "filter_query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"machine-learning-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = search(query, size=3, query_patch=filter_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "374166e7-87e2-4e84-a021-8185612f09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_shards\": {\n",
      "        \"failed\": 0,\n",
      "        \"skipped\": 0,\n",
      "        \"successful\": 1,\n",
      "        \"total\": 1\n",
      "    },\n",
      "    \"hits\": {\n",
      "        \"hits\": [\n",
      "            {\n",
      "                \"_id\": \"rTvZRZABteXuJDEWzTCq\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 84.050095,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"machine-learning-zoomcamp\",\n",
      "                    \"question\": \"How do I debug a docker container?\",\n",
      "                    \"section\": \"5. Deploying Machine Learning Models\",\n",
      "                    \"text\": \"Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\"\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"zDvZRZABteXuJDEW0DD2\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 51.04628,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"machine-learning-zoomcamp\",\n",
      "                    \"question\": \"How do I copy files from my local machine to docker container?\",\n",
      "                    \"section\": \"5. Deploying Machine Learning Models\",\n",
      "                    \"text\": \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\"\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"zTvZRZABteXuJDEW0TAU\",\n",
      "                \"_index\": \"course-questions\",\n",
      "                \"_score\": 49.938507,\n",
      "                \"_source\": {\n",
      "                    \"course\": \"machine-learning-zoomcamp\",\n",
      "                    \"question\": \"How do I copy files from a different folder into docker container\\u2019s working directory?\",\n",
      "                    \"section\": \"5. Deploying Machine Learning Models\",\n",
      "                    \"text\": \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\\\"src/predict.py\\\", \\\"models/xgb_model.bin\\\", \\\"./\\\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan\"\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"max_score\": 84.050095,\n",
      "        \"total\": {\n",
      "            \"relation\": \"eq\",\n",
      "            \"value\": 345\n",
      "        }\n",
      "    },\n",
      "    \"timed_out\": false,\n",
      "    \"took\": 18\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How do I copy files from a different folder into docker container’s working directory?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(json.dumps(response.body,sort_keys=True, indent=4))\n",
    "response[\"hits\"][\"hits\"][-1][\"_source\"][\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069aff71-a784-4ef9-a860-be5879ee7a2a",
   "metadata": {},
   "source": [
    "**Answer: 'How do I copy files from a different folder into docker container’s working directory?'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187235e2-0a2f-41a4-9dce-5562899a6c78",
   "metadata": {},
   "source": [
    "## Q5. Building a prompt\n",
    "\n",
    "Now we're ready to build a prompt to send to an LLM. \n",
    "\n",
    "Take the records returned from Elasticsearch in Q4 and use this template to build the context. Separate context entries by two linebreaks (`\\n\\n`)\n",
    "```python\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "Now use the context you just created along with the \"How do I execute a command in a running docker container?\" question \n",
    "to construct a prompt using the template below:\n",
    "\n",
    "```\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "What's the length of the resulting prompt? (use the `len` function)\n",
    "\n",
    "* 962\n",
    "* 1462\n",
    "* 1962\n",
    "* 2462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54181911-e6ac-4db0-9afe-f095248cfac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: How do I debug a docker container?\\nA: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nQ: How do I copy files from my local machine to docker container?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\\n\\nQ: How do I copy files from a different folder into docker container’s working directory?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "context_lines = []\n",
    "\n",
    "for rsp in response[\"hits\"][\"hits\"]:\n",
    "    _source=rsp[\"_source\"]\n",
    "    question = _source[\"question\"]\n",
    "    answer = _source['text']\n",
    "\n",
    "    context_lines.append(context_template.format(question=question, text=answer))\n",
    "\n",
    "\n",
    "context = '\\n\\n'.join(context_lines)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f89eaa9-cee9-4f3f-9a15-021f1ac6c2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: How do I execute a command in a running docker container?\\n\\nCONTEXT:\\nQ: How do I debug a docker container?\\nA: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nQ: How do I copy files from my local machine to docker container?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\\n\\nQ: How do I copy files from a different folder into docker container’s working directory?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = prompt_template.format(question=query, context=context)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c09dc604-2183-4838-a299-9424ae5796fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 1462'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Answer: {len(prompt)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ceecf-4a09-40f5-99ba-d615179a8bf4",
   "metadata": {},
   "source": [
    "## Q6. Tokens\n",
    "\n",
    "When we use the OpenAI Platform, we're charged by the number of \n",
    "tokens we send in our prompt and receive in the response.\n",
    "\n",
    "The OpenAI python package uses `tiktoken` for tokenization:\n",
    "\n",
    "```bash\n",
    "pip install tiktoken\n",
    "```\n",
    "\n",
    "Let's calculate the number of tokens in our query: \n",
    "\n",
    "```python\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "```\n",
    "\n",
    "Use the `encode` function. How many tokens does our prompt have?\n",
    "\n",
    "* 122\n",
    "* 222\n",
    "* 322\n",
    "* 422\n",
    "\n",
    "Note: to decode back a token into a word, you can use the `decode_single_token_bytes` function:\n",
    "\n",
    "```python\n",
    "encoding.decode_single_token_bytes(63842)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6acc6df5-0865-4f84-873a-f0078f64c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4afd704-a8dc-42a7-9e33-91793db3f148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 322'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "f'Answer: {len(encoding.encode(prompt))}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e111fb-2e9a-4da2-96fc-ae2a074e47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding.encode(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99c57fca-6286-4572-ace5-c8912c5baa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in encoding.encode(prompt): \n",
    "#     print(t, encoding.decode_single_token_bytes(t))\n",
    "# encoding.decode(encoding.encode(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274359e-f86b-4ad9-90b3-05ce9bba0a3f",
   "metadata": {},
   "source": [
    "## Bonus: generating the answer (ungraded)\n",
    "\n",
    "Let's send the prompt to OpenAI. What's the response?  \n",
    "\n",
    "Note: you can replace OpenAI with Ollama. See module 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "322ffccd-9719-46ba-874e-46f874ac4840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /usr/local/python/3.10.8/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/codespace/.local/lib/python3.10/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "160ea3b8-3d25-4c80-8fda-048f2b0a4c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499e8586eb8d2acec0c53cbeaa17d5363cc97a441f818452b3759758c8bf226e\n"
     ]
    }
   ],
   "source": [
    "!docker run -it -d --rm -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bb32a22-82bd-42d3-b161-3517654fa7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e73ddf7-a709-43a8-a6dc-9c7c60b31685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama.chat(model='llama3', messages=[\n",
    "#   {\n",
    "#     'role': 'user',\n",
    "#     'content': \"hello\",\n",
    "#   },\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d529ff0-a4d2-4250-98de-6928b9ad5b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, the answer to your question is:\n",
      "\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker exec -it <container-id> bash\n",
      "CPU times: user 11.9 ms, sys: 1.24 ms, total: 13.1 ms\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = ollama.chat(model='llama3', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': prompt,\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87edb550-09ca-400d-94c9-73b8c2dd9591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3',\n",
       " 'created_at': '2024-06-23T16:12:57.918941283Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'Based on the context, the answer to your question is:\\n\\nIf the container is already running, execute a command in the specific container:\\ndocker exec -it <container-id> bash'},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 116271618585,\n",
       " 'load_duration': 53561412,\n",
       " 'prompt_eval_count': 329,\n",
       " 'prompt_eval_duration': 97996022000,\n",
       " 'eval_count': 37,\n",
       " 'eval_duration': 18091943000}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f60f51-452b-442d-8b29-6a605b50a4ce",
   "metadata": {},
   "source": [
    "## Bonus: calculating the costs (ungraded)\n",
    "\n",
    "Suppose that on average per request we send 150 tokens and receive back 250 tokens.\n",
    "\n",
    "How much will it cost to run 1000 requests?\n",
    "\n",
    "You can see the prices [here](https://openai.com/api/pricing/)\n",
    "\n",
    "On June 17, the prices for gpt4o are:\n",
    "\n",
    "* Input: $0.005 / 1K tokens\n",
    "* Output: $0.015 / 1K tokens\n",
    "\n",
    "You can redo the calculations with the values you got in Q6 and Q7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7e4b29e-a9e6-4058-9253-153d6bf7f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of one request is: 0.0022.\n",
      "The cost of 1000 requests is: 2.15.\n"
     ]
    }
   ],
   "source": [
    "input_price = 0.005 / 1000 \n",
    "output_price = 0.015 / 1000 \n",
    "\n",
    "def cost(prompt: str, response: str, model:str=\"gpt-4o\",input_price:float=input_price,output_price:float=output_price):\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    input_length = len(enc.encode(prompt))\n",
    "    output_length = len(enc.encode(response))\n",
    "    \n",
    "    content_price = input_price * input_length\n",
    "    response_price = output_price * output_length\n",
    "    total_price = content_price + response_price\n",
    "\n",
    "    return total_price\n",
    "\n",
    "one_request_cost = cost(prompt, response['message']['content'])\n",
    "print(f\"The cost of one request is: {round(one_request_cost, 4)}.\")\n",
    "print(f\"The cost of 1000 requests is: {round(one_request_cost*(10**3), 4)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331e20f-e935-49f1-b559-6e75566ed631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10-env",
   "language": "python",
   "name": "py3.10-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
