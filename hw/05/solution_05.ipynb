{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b733a57-3b8b-45fa-9681-02f99549a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "which python\n",
    "python --version\n",
    "#python -m ipykernel install --name py3.10-env --user\n",
    "pip install -q tqdm openai elasticsearch pandas scikit-learn transformers accelerate bitsandbytes tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f472c0-3bb9-4415-9316-3ed82f1b638e",
   "metadata": {},
   "source": [
    "## Q1. Running Mage\n",
    "\n",
    "Clone the same repo we used in the module and run mage:\n",
    "\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/mage-ai/rag-project\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589b51fa-16d3-4022-81e3-fd5430a6254d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'rag-project'...\n",
      "remote: Enumerating objects: 60, done.\u001b[K\n",
      "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
      "remote: Total 60 (delta 14), reused 55 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (60/60), 14.14 KiB | 14.14 MiB/s, done.\n",
      "Resolving deltas: 100% (14/14), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mage-ai/rag-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88c86f-f435-4752-b393-9ce5451f3f95",
   "metadata": {},
   "source": [
    "Add the following libraries to the requirements document:\n",
    "\n",
    "```\n",
    "python-docx\n",
    "elasticsearch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7702721e-5a21-49eb-a563-04269f57d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"python-docx\" >> rag-project/llm/requirements.txt\n",
    "!echo \"elasticsearch\" >> rag-project/llm/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5321b6-9c65-4170-95fb-2a100b874f2a",
   "metadata": {},
   "source": [
    "Make sure you use the latest version of mage:\n",
    "\n",
    "```bash\n",
    "docker pull mageai/mageai:llm\n",
    "```\n",
    "\n",
    "Start it:\n",
    "\n",
    "```bash\n",
    "./scripts/start.sh\n",
    "```\n",
    "\n",
    "Now mage is running on [http://localhost:6789/](http://localhost:6789/)\n",
    "\n",
    "What's the version of mage? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbcccfb-1efe-49df-b9ce-c9fc57726e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm: Pulling from mageai/mageai\n",
      "\n",
      "\u001b[1B5d672725: Pulling fs layer \n",
      "\u001b[1B3c12a9c9: Pulling fs layer \n",
      "\u001b[1B43a5fa82: Pulling fs layer \n",
      "\u001b[1B1019d793: Pulling fs layer \n",
      "\u001b[1B72e87958: Pulling fs layer \n",
      "\u001b[1B7c53cd82: Pulling fs layer \n",
      "\u001b[1B4ae0623d: Pulling fs layer \n",
      "\u001b[1B92e7b73b: Pulling fs layer \n",
      "\u001b[1B1a75568b: Pulling fs layer \n",
      "\u001b[1Bfadde973: Pulling fs layer \n",
      "\u001b[1Be10f7a13: Pulling fs layer \n",
      "\u001b[1Baa005a6d: Pulling fs layer \n",
      "\u001b[1B1b4caa66: Pulling fs layer \n",
      "\u001b[1B704b6e4e: Pulling fs layer \n",
      "\u001b[1Bfbaa3ccb: Pulling fs layer \n",
      "\u001b[1B9c2cb1f1: Pull complete  112B/112B3kBB\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[11A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[6A\u001b[2K\u001b[13A\u001b[2K\u001b[6A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[6A\u001b[2K\u001b[16A\u001b[2K\u001b[6A\u001b[2K\u001b[16A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[15A\u001b[2K\u001b[5A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:d3c4dee9f04ee466a200b1390530e03049e74f5f86541cc2ff15b4d586d866ea\n",
      "Status: Downloaded newer image for mageai/mageai:llm\n",
      "docker.io/mageai/mageai:llm\n"
     ]
    }
   ],
   "source": [
    "!docker pull mageai/mageai:llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45056c2f-6865-405c-a004-e41c72f7afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd ./rag-project && ./scripts/start.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965205bc-0215-44c5-8401-87b6ef4a355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v0.9.72'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"v0.9.72\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537dc832-0fda-4289-b231-e2eea0451a7f",
   "metadata": {},
   "source": [
    "\n",
    "## Creating a RAG pipeline\n",
    "\n",
    "Create a RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfb852-8408-4c76-92bc-51fe4b9656cd",
   "metadata": {},
   "source": [
    "## Q2. Reading the documents\n",
    "\n",
    "Now we can ingest the documents. Create a custom code ingestion\n",
    "block \n",
    "\n",
    "Let's read the documents. We will use the same code we used\n",
    "for parsing FAQ: [parse-faq-llm.ipynb](parse-faq-llm.ipynb)\n",
    "\n",
    "\n",
    "Use the following document_id: 1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E\n",
    "\n",
    "Which is the document ID of\n",
    "[LLM FAQ version 1](https://docs.google.com/document/d/1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E/edit)\n",
    "\n",
    "Copy the code to the editor\n",
    "How many FAQ documents we processed?\n",
    "\n",
    "* **1**\n",
    "* 2\n",
    "* 3\n",
    "* 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbb94b-1780-4aba-bd48-ea6757e74212",
   "metadata": {},
   "source": [
    "## Q3. Chunking\n",
    "\n",
    "We don't really need to do any chuncking because our documents\n",
    "already have well-specified boundaries. So we just need\n",
    "to return the documents without any changes.\n",
    "\n",
    "So let's go to the transformation part and add a custom code\n",
    "chunking block:\n",
    "\n",
    "```python\n",
    "documents = []\n",
    "\n",
    "for doc in data['documents']:\n",
    "    doc['course'] = data['course']\n",
    "    # previously we used just \"id\" for document ID\n",
    "    doc['document_id'] = generate_document_id(doc)\n",
    "    documents.append(doc)\n",
    "\n",
    "print(len(documents))\n",
    "\n",
    "return documents\n",
    "```\n",
    "\n",
    "\n",
    "Where `data` is the input parameter to the transformer.\n",
    "\n",
    "And the `generate_document_id` is defined in the same way\n",
    "as in module 4:\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id\n",
    "```\n",
    "\n",
    "Note: if instead of a single dictionary you get a list, \n",
    "add a for loop:\n",
    "\n",
    "```python\n",
    "for course_dict in data:\n",
    "    ...\n",
    "```\n",
    "\n",
    "You can check the type of `data` with this code:\n",
    "\n",
    "```python\n",
    "print(type(data))\n",
    "```\n",
    "\n",
    "How many documents (chunks) do we have in the output?\n",
    "\n",
    "* 66\n",
    "* 76\n",
    "* **86**\n",
    "* 96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf9b4db-71fd-4452-b6c0-48534f6a87c5",
   "metadata": {},
   "source": [
    "```\n",
    "documents = []\n",
    "course = data[0]['course']\n",
    "docs = data[0]['documents']\n",
    "\n",
    "for doc in docs:\n",
    "    doc['course'] = course\n",
    "    # previously we used just \"id\" for document ID\n",
    "    doc['document_id'] = generate_document_id(doc)\n",
    "    documents.append(doc)\n",
    "\n",
    "print(len(documents))\n",
    "\n",
    "return documents\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b4673-8869-49d4-b7b5-3c344f8b091e",
   "metadata": {},
   "source": [
    "\n",
    "## Tokenization and embeddings\n",
    "\n",
    "We don't need any tokenization, so we skip it.\n",
    "\n",
    "Because currently it's required in mage, we can create \n",
    "a dummy code block:\n",
    "\n",
    "* Create a custom code block\n",
    "* Don't change it\n",
    "\n",
    "Because we will use text search, we also don't need embeddings,\n",
    "so skip it too.\n",
    "\n",
    "If you want to use sentence transformers - the ones from module\n",
    "3 - you don't need tokenization, but need embeddings\n",
    "(you don't need it for this homework)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aeff89-5f0a-4c09-88ae-1453e1b159f4",
   "metadata": {},
   "source": [
    "## Q4. Export\n",
    "\n",
    "Now we're ready to index the data with elasticsearch. For that,\n",
    "we use the Export part of the pipeline\n",
    "\n",
    "* Go to the Export part\n",
    "* Select vector databases -> Elasticsearch\n",
    "* Open the code for editing\n",
    "\n",
    "Because we won't use vector search, but usual text search, we\n",
    "will need to adjust the code.\n",
    "\n",
    "First, let's change the line where we read the index name:\n",
    "\n",
    "```python\n",
    "index_name = kwargs.get('index_name', 'documents')\n",
    "``` \n",
    "\n",
    "To `index_name_prefix` - we will parametrize it with the day\n",
    "and time we run the pipeline\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "\n",
    "index_name_prefix = kwargs.get('index_name', 'documents')\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n",
    "index_name = f\"{index_name_prefix}_{current_time}\"\n",
    "print(\"index name:\", index_name)\n",
    "```\n",
    "\n",
    "\n",
    "We will need to save the name in a global variable, so it can be accessible in other code blocks\n",
    "\n",
    "```python\n",
    "from mage_ai.data_preparation.variable_manager import set_global_variable\n",
    "\n",
    "set_global_variable('YOUR_PIPELINE_NAME', 'index_name', index_name)\n",
    "```\n",
    "\n",
    "Where your pipeline name is the name of the pipeline, e.g.\n",
    "`transcendent_nexus` (replace the space with underscore `_`)\n",
    "\n",
    "\n",
    "\n",
    "Replace index settings with the settings we used previously:\n",
    "\n",
    "```python\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": number_of_shards,\n",
    "        \"number_of_replicas\": number_of_replicas\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"document_id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Remove the embeddings line:\n",
    "\n",
    "```python\n",
    "if isinstance(document[vector_column_name], np.ndarray):\n",
    "    document[vector_column_name] = document[vector_column_name].tolist()\n",
    "```\n",
    "\n",
    "At the end (outside of the indexing for loop), print the last document:\n",
    "\n",
    "```python\n",
    "print(document)\n",
    "```\n",
    "\n",
    "Now execute the block.\n",
    "\n",
    "What's the last document id?\n",
    "\n",
    "Also note the index name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78047edb-f998-4a3e-900c-779cbc214e31",
   "metadata": {},
   "source": [
    "```python\n",
    "@data_exporter\n",
    "def elasticsearch(\n",
    "    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Exports document data to an Elasticsearch database.\n",
    "    \"\"\"\n",
    "\n",
    "    from mage_ai.data_preparation.variable_manager import set_global_variable\n",
    "\n",
    "\n",
    "    connection_string = kwargs.get('connection_string', 'http://rag-project-elasticsearch-1:9200')\n",
    "    #index_name = kwargs.get('index_name', 'documents')\n",
    "\n",
    "    index_name_prefix = kwargs.get('index_name', 'documents')\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n",
    "    index_name = f\"{index_name_prefix}_{current_time}\"\n",
    "    print(\"index name:\", index_name)\n",
    "    set_global_variable('mesmerizing_singularity', 'index_name', index_name)\n",
    "    number_of_shards = kwargs.get('number_of_shards', 1)\n",
    "    number_of_replicas = kwargs.get('number_of_replicas', 0)\n",
    "    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n",
    "\n",
    "    dimensions = kwargs.get('dimensions')\n",
    "    if dimensions is None and len(documents) > 0:\n",
    "        document = documents[0]\n",
    "        dimensions = len(document.get(vector_column_name) or [])\n",
    "\n",
    "    es_client = Elasticsearch(connection_string)\n",
    "\n",
    "    print(f'Connecting to Elasticsearch at {connection_string}')\n",
    "\n",
    "    index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": number_of_shards,\n",
    "            \"number_of_replicas\": number_of_replicas\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"section\": {\"type\": \"text\"},\n",
    "                \"question\": {\"type\": \"text\"},\n",
    "                \"course\": {\"type\": \"keyword\"},\n",
    "                \"document_id\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #index_settings = dict(\n",
    "    #    settings=dict(\n",
    "    #        number_of_shards=number_of_shards,\n",
    "    #        number_of_replicas=number_of_replicas,\n",
    "    #    ),\n",
    "    #    mappings=dict(\n",
    "    #        properties=dict(\n",
    "    #            chunk=dict(type='text'),\n",
    "    #            document_id=dict(type='text'),\n",
    "    #            embedding=dict(type='dense_vector', dims=dimensions),\n",
    "    #        ),\n",
    "    #    ),\n",
    "    #)\n",
    "\n",
    "    if not es_client.indices.exists(index=index_name):\n",
    "        es_client.indices.create(index=index_name)\n",
    "        print('Index created with properties:', index_settings)\n",
    "        print('Embedding dimensions:', dimensions)\n",
    "\n",
    "    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n",
    "    for document in documents:\n",
    "        print(f'Indexing document {document[\"document_id\"]}')\n",
    "\n",
    "        #if isinstance(document[vector_column_name], np.ndarray):\n",
    "        #    document[vector_column_name] = document[vector_column_name].tolist()\n",
    "\n",
    "        es_client.index(index=index_name, document=document)\n",
    "    print(document)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c33de-44a6-4ede-8fa3-0dfd768f5749",
   "metadata": {},
   "source": [
    "index name: documents_20240819_0416\n",
    "```json\n",
    "{'text': 'Yes, you need to pass the Capstone project to get the certificate. Homework is not mandatory, though it is recommended for reinforcing concepts, and the points awarded count towards your rank on the leaderboard.', 'section': 'General course-related questions', 'question': 'I missed the first homework - can I still get a certificate?', 'course': 'llm-zoomcamp', 'document_id': 'fa136280'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44850221-a6c5-4ab4-8d73-8f7dca65cc95",
   "metadata": {},
   "source": [
    "## Q5. Testing the retrieval\n",
    "\n",
    "Now let's test the retrieval. Use mage or jupyter notebook to\n",
    "test it.\n",
    "\n",
    "Let's use the following query: \"When is the next cohort?\"\n",
    "\n",
    "What's the ID of the top matching result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e770425b-2be9-4083-bc48-f90ffe5b8c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '1cdf405c2a67',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'sPJ4rh_NQq6klLrJ2OPo5g',\n",
       " 'version': {'number': '8.5.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': 'c94b4700cda13820dad5aa74fae6db185ca5c304',\n",
       "  'build_date': '2022-10-24T16:54:16.433628434Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.4.1',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "es_client.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "635cccd0-c924-4d25-84ba-cc5373c9a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"documents_20240819_0416\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ae4a44-0f66-40c2-8cdd-e6b4a962351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_dicts(a: dict, b: dict, path=[]):\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            if isinstance(a[key], dict) and isinstance(b[key], dict):\n",
    "                _merge_dicts(a[key], b[key], path + [str(key)])\n",
    "            elif a[key] != b[key]:\n",
    "                raise Exception('Conflict at ' + '.'.join(path + [str(key)]))\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a\n",
    "    \n",
    "def search(q, index = index_name, es_client=es_client, size=5, fields=None, type_match=\"best_fields\", query_patch:dict = None):\n",
    "    fields = fields or [\"question^4\", \"text\"]\n",
    "    query_patch = query_patch or {}\n",
    "    search_query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": fields,\n",
    "                        \"type\": type_match\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    search_query = _merge_dicts(search_query,query_patch) if query_patch else search_query\n",
    "    return es_client.search(index=index, body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5e51de-a2a9-4358-a0c9-0f3496df79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When is the next cohort?\"\n",
    "\n",
    "response = search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49326945-dbeb-41ae-9447-43395d5c51bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'documents_20240819_0416',\n",
       " '_id': 'EXnibJEBUptsjNsiUjeI',\n",
       " '_score': 33.77578,\n",
       " '_source': {'text': 'Summer 2025 (via Alexey).',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'When will the course be offered next?',\n",
       "  'course': 'llm-zoomcamp',\n",
       "  'document_id': 'bf024675'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"hits\"][\"hits\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07293494-2c21-4f5a-8da8-f792081dc176",
   "metadata": {},
   "source": [
    "## Q6. Reindexing\n",
    "\n",
    "Our FAQ document changes: every day course participants add\n",
    "new records or improve existing ones.\n",
    "\n",
    "Imagine some time passed and the document changed. For that we have another version of the FAQ document: [version 2](https://docs.google.com/document/d/1T3MdwUvqCL3jrh3d3VCXQ8xE0UqRzI3bfgpfBq3ZWG0/edit).\n",
    "\n",
    "The ID of this document is `1T3MdwUvqCL3jrh3d3VCXQ8xE0UqRzI3bfgpfBq3ZWG0`.\n",
    "\n",
    "Let's re-execute the entire pipeline with the updated data.\n",
    "\n",
    "For the same query \"When is the next cohort?\". What's the ID of the top matching result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecce42ca-611f-47c3-98b6-23cf672f96b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'documents_20240820_0416',\n",
       " '_id': '09IAbZEBJy6ui47HOUNS',\n",
       " '_score': 68.84985,\n",
       " '_source': {'text': 'Summer 2026.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'When is the next cohort?',\n",
       "  'course': 'llm-zoomcamp',\n",
       "  'document_id': 'b6fa77f3'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "query = \"When is the next cohort?\"\n",
    "\n",
    "response = search(query, index=\"documents_20240820_0416\")\n",
    "response[\"hits\"][\"hits\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c351562-3080-4154-819f-b5d9d553eb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10-env",
   "language": "python",
   "name": "py3.10-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
